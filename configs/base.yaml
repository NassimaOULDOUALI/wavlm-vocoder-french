# WavLM Vocoder - Base Configuration
# No GAN training (spectral losses only)

model:
  wavlm_model_name: "/lustre/fsn1/projects/rech/lsq/umv83if/hf_models/microsoft_wavlm_base_plus"
  hidden_dim: 256
  num_adapter_layers: 3
  kernel_size: 7
  freeze_wavlm: true
  dropout: 0.1
  
  # Layer fusion
  num_layers: 12  # Use all 12 layers
  fusion_type: "learned"  # or "average"

loss:
  # Reconstruction losses
  l1_weight: 1.0
  stft_weight: 45.0
  
  # GAN losses (disabled for base config)
  use_gan: false
  adv_weight: 1.0
  fm_weight: 2.0

data:
  train_dir: "/lustre/fsn1/projects/rech/lsq/umv83if/filtered"
  val_dir: "/lustre/fsn1/projects/rech/lsq/umv83if/filtered/common_voice_fr/validation"
  segment_length: 32000  # 2 seconds at 16kHz
  sample_rate: 16000
  use_rms_norm: false
  rms_threshold: 0.005
  peak_target: 0.95

training:
  # Optimizer
  lr: 0.0002
  betas: [0.8, 0.99]
  weight_decay: 0.00
  
  # Training
  batch_size: 16  # per GPU
  num_epochs: 50
  grad_clip: 5.0
  use_amp: true
  
  warmup_steps: 10000
  
  # Checkpointing
  output_dir: "./outputs"
  save_interval: 5000
  eval_interval: 10000
  
  # Data loading
  num_workers: 4
  
  # Resume
  resume: false
  checkpoint_path: null
  
  # Distributed
  distributed: true
  world_size: 4

logging:
  log_interval: 10
  tensorboard: true
  wandb: false
  wandb_project: "wavlm-vocoder"
